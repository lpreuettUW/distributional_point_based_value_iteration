# Distributional Point-Based Value Iteration (DPBVI)

This repository contains implementations of several reinforcement learning algorithms for solving Markov Decision Processes (MDPs) and Partially Observable Markov Decision Processes (POMDPs), including:
1. **Value Iteration (VI)** ‚Äì [Sutton & Barto, 2018](http://incompleteideas.net/book/the-book-2nd.html)
2. **Distributional Value Iteration (DVI)** ‚Äì [Bellemare et al., 2023](https://www.distributional-rl.org/)
3. **Point-Based Value Iteration (PBVI)** ‚Äì [Pineau et al., 2003](http://www.cs.cmu.edu/~ggordon/jpineau-ggordon-thrun.ijcai03.pdf) 
4. **Distributional Point-Based Value Iteration (DPBVI)** ‚Äì Our proposed method, extending PBVI to the distributional reinforcement learning setting.

## üìÇ Repository Structure
```
distributional_point_based_value_iteration/
‚îÇ‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ dvi.py        # Distributional Value Iteration (DVI) implementation
‚îÇ   ‚îú‚îÄ‚îÄ pbvi.py       # Point-Based Value Iteration (PBVI) implementation
‚îÇ   ‚îú‚îÄ‚îÄ dpbvi.py      # Distributional PBVI (DPBVI) implementation (our work)
‚îú‚îÄ‚îÄ vi_cliff_walking_example.py   # Value Iteration on Cliff Walking environment
‚îú‚îÄ‚îÄ dvi_cliff_walking_example.py  # DVI evaluation on Cliff Walking
‚îú‚îÄ‚îÄ minigrid_eval.py              # PBVI & DPBVI evaluation on MiniGrid-DoorKey-5x5-v0
‚îú‚îÄ‚îÄ trivial_example.py            # PBVI & DPBVI evaluation on noisy two-state problem
‚îú‚îÄ‚îÄ minigrid_counters.pkl         # Recorded observations & transitions (used for extracting transition and sensor models)
‚îÇ‚îÄ‚îÄ README.md
‚îÇ‚îÄ‚îÄ requirements.txt
‚îÇ‚îÄ‚îÄ LICENSE
```

## üìù Implemented Algorithms

### 1Ô∏è‚É£ **Value Iteration (VI)**
- Implements classical **value iteration** for MDPs.
- **File:** `vi_cliff_walking_example.py`
- **Reference:** Sutton & Barto, *Reinforcement Learning: An Introduction (2018)*.

### 2Ô∏è‚É£ **Distributional Value Iteration (DVI)**
- Implements **distributional RL** for solving MDPs.
- **Files:**
  - Implementation: `agents/dvi.py`
  - Evaluation: `dvi_cliff_walking_example.py`
- **Reference:** Bellemare et al., *Distributional Reinforcement Learning (2023)*.

### 3Ô∏è‚É£ **Point-Based Value Iteration (PBVI)**
- Implements **point-based** methods for solving POMDPs.
- **Files:**
  - Implementation: `agents/pbvi.py`
  - Evaluation: `minigrid_eval.py`, `trivial_example.py`
- **Reference:** Pineau et al., *Point-Based Value Iteration: An Anytime Algorithm for POMDPs (2003)*.

### 4Ô∏è‚É£ **Distributional Point-Based Value Iteration (DPBVI)**
- **Our proposed method**, extending PBVI with **distributional RL concepts**.
- **Files:**
  - Implementation: `agents/dpbvi.py`
  - Evaluation: `minigrid_eval.py`, `trivial_example.py`
- **Key Environments:**
  - **MiniGrid-DoorKey-5x5-v0** ‚Äì Adapted from [MiniGrid](https://github.com/Farama-Foundation/Minigrid).
  - **Noisy Two-State Problem** ‚Äì Adapted from [Norvig & Russell's Artificial Intelligence: A Modern Approach (Section 17.5)](http://aima.cs.berkeley.edu/).

## üèóÔ∏è Installation (Using Conda)

### **1Ô∏è‚É£ Clone the repository**
```
git clone https://github.com/lpreuettUW/distributional_point_based_value_iteration.git
cd distributional_point_based_value_iteration
```

### **2Ô∏è‚É£ Create and activate a Conda environment**
Ensure you have Conda installed, then create an environment with Python 3.11:
```
conda create --name dpbvi-env python=3.11
conda activate dpbvi-env
```

### **3Ô∏è‚É£ Install dependencies**
```
pip install -r requirements.txt
```

## üöÄ Running Experiments

### Run Value Iteration (VI) on Cliff Walking:
```
python vi_cliff_walking_example.py
```

### Run Distributional Value Iteration (DVI) on Cliff Walking:
```
python dvi_cliff_walking_example.py
```

### Run PBVI / DPBVI on MiniGrid:
```
python minigrid_eval.py
```

### Run PBVI / DPBVI on Two-State Problem:
```
python trivial_example.py
```

## üìú License

This repository is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
